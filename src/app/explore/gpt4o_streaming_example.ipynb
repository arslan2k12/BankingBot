{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1c7ebc",
   "metadata": {},
   "source": [
    "# GPT-4o Streaming Example\n",
    "\n",
    "This notebook demonstrates how to initialize GPT-4o with streaming enabled and invoke it with a simple \"hello world\" message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30664f",
   "metadata": {},
   "source": [
    "## Install Required Dependencies\n",
    "\n",
    "Install the OpenAI Python client library using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d771e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110e3e4",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Import the OpenAI client and other necessary libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "from typing import Generator\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d5a96",
   "metadata": {},
   "source": [
    "## Initialize GPT-4o Model with Streaming\n",
    "\n",
    "Set up the OpenAI client and configure the GPT-4o model with streaming enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d8b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # Make sure to set this in your .env file\n",
    ")\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"gpt-4o\"  # GPT-4o model\n",
    "TEMPERATURE = 0.7\n",
    "MAX_TOKENS = 150\n",
    "\n",
    "print(f\"üöÄ OpenAI client initialized successfully!\")\n",
    "print(f\"ü§ñ Model: {MODEL_NAME}\")\n",
    "print(f\"üå°Ô∏è  Temperature: {TEMPERATURE}\")\n",
    "print(f\"üìè Max tokens: {MAX_TOKENS}\")\n",
    "print(f\"üîÑ Streaming: Enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ed9b9",
   "metadata": {},
   "source": [
    "## Invoke Model with Hello World\n",
    "\n",
    "Create a chat completion request with a simple 'hello world' message and enable streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b2d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the message\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful and friendly AI assistant. Respond in a warm and engaging manner.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello world! Tell me something interesting about yourself.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üí¨ Message prepared:\")\n",
    "print(f\"   System: {messages[0]['content'][:50]}...\")\n",
    "print(f\"   User: {messages[1]['content']}\")\n",
    "print(\"\\nüöÄ Invoking GPT-4o with streaming...\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dd1597",
   "metadata": {},
   "source": [
    "## Handle Streaming Response\n",
    "\n",
    "Process and display the streaming response from the model in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90157f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create streaming chat completion\n",
    "try:\n",
    "    # Make the streaming request\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        stream=True  # Enable streaming\n",
    "    )\n",
    "    \n",
    "    print(\"ü§ñ GPT-4o Response (Streaming):\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Collect the full response\n",
    "    full_response = \"\"\n",
    "    \n",
    "    # Process streaming chunks\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            full_response += content\n",
    "            print(content, end=\"\", flush=True)  # Print in real-time\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    print(f\"‚úÖ Streaming completed successfully!\")\n",
    "    print(f\"üìä Total response length: {len(full_response)} characters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error occurred during streaming: {str(e)}\")\n",
    "    print(\"üîç Please check your API key and internet connection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bankbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
